{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using invariant representations to guide future exploration\n",
    "\n",
    "I would like to further explore an idea of leveraging abstract concepts learned from previous experiences to help aid and guide the behavior of an agent when faced with a novel problem. The aim is to sequentially construct and expand agent's knowledge base, and use it to construct a behavioral policy that would guide the exploration while learning the optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import wandb\n",
    "\n",
    "from gym.wrappers.pixel_observation import PixelObservationWrapper\n",
    "from tianshou.utils import WandbLogger\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.abspath(os.path.join('.')) not in sys.path:\n",
    "    sys.path.append(os.path.abspath(os.path.join('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Task\n",
    "from models.trainer import DQNTrainer\n",
    "from models.wrappers import PreprocessObservation, StackObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"lldqn\"\n",
    "WANDB_LOG_DIR = \"./data\"\n",
    "WANDB_TENSORBOARD = \"./data/tensorboard\"\n",
    "TASKS = [\n",
    "    dict(\n",
    "        env_name=\"CartPole-v1\",\n",
    "        save_data_dir=\"./data/models\",\n",
    "        use_baseline=True,\n",
    "        wrappers=[\n",
    "            (PixelObservationWrapper, {\"pixels_only\": False}),\n",
    "            (PreprocessObservation, {}),\n",
    "            (StackObservation, {}),\n",
    "        ],\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_data in TASKS:\n",
    "    for repeat in range(1):\n",
    "        task = Task(**task_data, version=repeat + 1)\n",
    "\n",
    "        wandb.init(\n",
    "            project=WANDB_PROJECT,\n",
    "            dir=WANDB_LOG_DIR,\n",
    "            group=task.name,\n",
    "            job_type=\"Policy-Train\",\n",
    "            name=task.save_model_name,\n",
    "            sync_tensorboard=True,\n",
    "            reinit=True,\n",
    "            monitor_gym=True,\n",
    "            config={\n",
    "                \"train/repeat_count\": 1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        logger = WandbLogger()\n",
    "        logger.load(SummaryWriter(WANDB_TENSORBOARD))\n",
    "        trainer = DQNTrainer(task, logger=logger)\n",
    "        result = trainer.run()\n",
    "\n",
    "        print(\"Finished repeat {}. Time taken: {:.4}s\".format(repeat + 1, result[\"duration\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('lifelong_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33431a34c2fc9292c5ffdbeed9358857b48cb59106e4a69bd1d3c3cefbd11921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
